{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d937048c-6b2f-45e6-b8c8-7e5d702e02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 mises à jour.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Commit après 100 insertions.\n",
      "Nombre de lignes lues dans 'silver_mastodon': 2761\n",
      "Nombre de posts mis à jour dans 'gold_mastodon': 1166\n",
      "Nombre de nouveaux posts insérés dans 'gold_mastodon': 1595\n",
      "Nombre total de posts dans 'gold_mastodon': 2761\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "\n",
    "# Fonction pour analyser le sentiment\n",
    "def analyze_sentiment(content):\n",
    "    if content:\n",
    "        analysis = TextBlob(content)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return \"positif\"\n",
    "        elif analysis.sentiment.polarity < 0:\n",
    "            return \"négatif\"\n",
    "        else:\n",
    "            return \"neutre\"\n",
    "    return \"neutre\"\n",
    "\n",
    "# 1. Création d'une session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MastodonDataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Connexion à la base de données PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/\" + os.getenv('DB_NAME')\n",
    "properties = {\n",
    "    \"user\": os.getenv('DB_USER'),\n",
    "    \"password\": os.getenv('DB_PASSWORD'),\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Connexion pour exécuter des commandes SQL\n",
    "conn = None\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=os.getenv('DB_NAME'),\n",
    "        user=os.getenv('DB_USER'),\n",
    "        password=os.getenv('DB_PASSWORD'),\n",
    "        host=\"postgres\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 3. Création de la table gold_mastodon si elle n'existe pas\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gold_mastodon (\n",
    "        post_id BIGINT PRIMARY KEY,\n",
    "        username VARCHAR(255),\n",
    "        content TEXT,\n",
    "        total_engagement INTEGER,\n",
    "        created_at TIMESTAMP,\n",
    "        hashtags TEXT,\n",
    "        sentiment_category VARCHAR(50),\n",
    "        average_engagement_per_post DOUBLE PRECISION\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # 4. Lit les données depuis la table silver_mastodon\n",
    "    posts_df = spark.read.jdbc(url=jdbc_url, table=\"silver_mastodon\", properties=properties)\n",
    "\n",
    "    # 5. Compte le nombre de lignes lues dans la table silver_mastodon\n",
    "    silver_count = posts_df.count()\n",
    "\n",
    "    # 6. Calcule les statistiques nécessaires\n",
    "    aggregated_df = posts_df.groupBy(\"id\", \"username\", \"cleaned_content\", \"created_at\") \\\n",
    "        .agg(\n",
    "            (F.sum(\"favourites_count\") + F.sum(\"reblogs_count\") + F.sum(\"replies_count\")).alias(\"total_engagement\"),\n",
    "            F.concat_ws(\", \", F.collect_list(\"hashtags\")).alias(\"hashtags\"),  # Transformation en texte brut\n",
    "            F.avg(\"engagement_count\").alias(\"average_engagement_per_post\")\n",
    "        )\n",
    "\n",
    "    # 7. Renomme les colonnes\n",
    "    aggregated_df = aggregated_df.withColumnRenamed(\"cleaned_content\", \"content\") \\\n",
    "        .withColumnRenamed(\"id\", \"post_id\")\n",
    "\n",
    "    # 8. Lit les données existantes dans gold_mastodon\n",
    "    existing_gold_df = spark.read.jdbc(url=jdbc_url, table=\"gold_mastodon\", properties=properties)\n",
    "\n",
    "    # 9. Identifie les posts à mettre à jour\n",
    "    posts_to_update_df = aggregated_df.join(existing_gold_df, on=\"post_id\", how=\"inner\")\n",
    "\n",
    "    # 10. Identifie les nouveaux posts à insérer\n",
    "    posts_to_insert_df = aggregated_df.join(existing_gold_df, on=\"post_id\", how=\"left_anti\")\n",
    "\n",
    "    # Analyse le sentiment pour les nouveaux posts\n",
    "    sentiment_analysis_udf = F.udf(analyze_sentiment, StringType())\n",
    "    posts_to_insert_df = posts_to_insert_df.withColumn(\"sentiment_category\", sentiment_analysis_udf(F.col(\"content\")))\n",
    "\n",
    "    # Compte les nouveaux posts à insérer\n",
    "    new_posts_count = posts_to_insert_df.count()\n",
    "\n",
    "    # Défini la taille du batch\n",
    "    batch_size = 100\n",
    "    update_counter = 0\n",
    "    insert_counter = 0\n",
    "\n",
    "    # 12. Met à jour les posts existants en batch\n",
    "    updated_count = 0  # Compteur pour les mises à jour\n",
    "    if posts_to_update_df.count() > 0:\n",
    "        update_query = \"\"\"\n",
    "        UPDATE gold_mastodon SET \n",
    "            total_engagement = %s, \n",
    "            average_engagement_per_post = %s,\n",
    "            sentiment_category = %s\n",
    "        WHERE post_id = %s\n",
    "        \"\"\"\n",
    "        for row in posts_to_update_df.collect():\n",
    "            cursor.execute(update_query, (\n",
    "                row.total_engagement, \n",
    "                row.average_engagement_per_post,\n",
    "                row.sentiment_category,\n",
    "                row.post_id\n",
    "            ))\n",
    "            update_counter += 1\n",
    "            updated_count += 1  # Incrémenter le compteur global\n",
    "\n",
    "            # Commit toutes les 100 mises à jour\n",
    "            if update_counter >= batch_size:\n",
    "                conn.commit()\n",
    "                print(f\"Commit après {update_counter} mises à jour.\")\n",
    "                update_counter = 0\n",
    "\n",
    "        # Commit final si des mises à jour sont restées non commit\n",
    "        if update_counter > 0:\n",
    "            conn.commit()\n",
    "\n",
    "    # Insére les nouveaux posts en batch\n",
    "    if new_posts_count > 0:\n",
    "        for row in posts_to_insert_df.collect():\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO gold_mastodon (post_id, username, content, total_engagement, created_at, hashtags, sentiment_category, average_engagement_per_post)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(insert_query, (\n",
    "                row.post_id,\n",
    "                row.username,\n",
    "                row.content,\n",
    "                row.total_engagement,\n",
    "                row.created_at,\n",
    "                row.hashtags,\n",
    "                row.sentiment_category,\n",
    "                row.average_engagement_per_post\n",
    "            ))\n",
    "            insert_counter += 1\n",
    "\n",
    "            # Commit toutes les 100 insertions\n",
    "            if insert_counter >= batch_size:\n",
    "                conn.commit()\n",
    "                print(f\"Commit après {insert_counter} insertions.\")\n",
    "                insert_counter = 0\n",
    "\n",
    "        # Commit final si des insertions sont restées non commit\n",
    "        if insert_counter > 0:\n",
    "            conn.commit()\n",
    "\n",
    "    # 14. Affiche les données mises à jour\n",
    "    gold_data_updated_df = spark.read.jdbc(url=jdbc_url, table=\"gold_mastodon\", properties=properties)\n",
    "    \n",
    "    # Compte le nombre total de posts dans gold_mastodon après les opérations\n",
    "    total_gold_count = gold_data_updated_df.count()\n",
    "\n",
    "    # Impressions finales\n",
    "    print(f\"Nombre de lignes lues dans 'silver_mastodon': {silver_count}\")\n",
    "    print(f\"Nombre de posts mis à jour dans 'gold_mastodon': {updated_count}\")\n",
    "    print(f\"Nombre de nouveaux posts insérés dans 'gold_mastodon': {new_posts_count}\")  \n",
    "    print(f\"Nombre total de posts dans 'gold_mastodon': {total_gold_count}\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()  # Annule la transaction en cas d'erreur\n",
    "    print(f\"Une erreur est survenue : {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Arrête la session Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7f1e6-898e-4768-b921-030ab2e624e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
